{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d9e6cc6-af39-4508-a908-d35330c6dfbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Parte 3:   Escenarios de Soporte\n",
    "*   **Autor:** Carolina Torres Zapata\n",
    "*   **Fecha:** 2025-11-24\n",
    "*   **Contexto:** En la operación diaria, los \"caminos felices\" son raros. Los datos cambian (Schema Drift), los despliegues fallan por mala configuración y el código optimizado incorrectamente rompe la producción.\n",
    "*   **Objetivo del Notebook:**\n",
    "Resolver tres incidentes simulados aplicando buenas prácticas:\n",
    "     1.  **Escenario 3.1:** Robustecer un pipeline de inferencia ante cambios inesperados en los datos de entrada.\n",
    "     2.  **Escenario 3.2:** Corregir la carga de modelos utilizando la API programática de MLflow para evitar errores de hardcoding.\n",
    "     3.  **Escenario 3.3:** Reparar un bug lógico en el sistema de recuperación (RAG) utilizando operaciones vectorizadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3db3362-1851-4e7b-854a-5a0b1c5f8fb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Escenario 3.1: Schema drift en datos de entrada\n",
    "\n",
    "### Diagnóstico y Corrección\n",
    "\n",
    "**Qué estaba mal:**\n",
    "El uso directo (`df_scoring.select(cols)`) es frágil; falla inmediatamente con un `AnalysisException` si el dataset de inferencia tiene una columna menos o un nombre diferente (Drift), y no gestiona columnas nuevas que podrían ensuciar el proceso.\n",
    "\n",
    "**Corrección:**\n",
    "1.  **Renombrado:** Normalización de nombres mediante un diccionario de equivalencias para manejar variaciones comunes.\n",
    "2.  **Imputación:** Creación automática de columnas faltantes con `NULL` para mantener el esquema requerido.\n",
    "3. **Validación de Tipos:** Conversión explícita (`cast`) de cada columna al tipo de dato esperado por el modelo.\n",
    "3.  **Selección:** Filtrado final explícito para ordenar columnas y descartar atributos extra no utilizados por el modelo.\n",
    "\n",
    "**Por qué es adecuada:**\n",
    "Esta solución asegura la **resiliencia operativa**. El pipeline no se detiene por cambios menores en la fuente, garantizando que el modelo siempre reciba la matriz de características exacta que espera para predecir, protegiendo la continuidad del servicio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "962a6277-05de-4a07-90af-b04a35f858ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# IMPORTAR LIBRERÍAS\n",
    "# =====================================\n",
    "from pyspark.sql.functions import col, lit\n",
    "import mlflow\n",
    "\n",
    "# =====================================\n",
    "# 1. ESQUEMA ESPERADO\n",
    "# =====================================\n",
    "expected_cols = df_train.columns\n",
    "expected_schema = dict(df_train.dtypes)\n",
    "\n",
    "print(f\"Columnas esperadas por el modelo: {len(expected_cols)}\")\n",
    "\n",
    "# ===============================================================\n",
    "# 2. MAPEO DE NOMBRES DE COLUMNAS (Name Normalization)\n",
    "# ===============================================================\n",
    "# Este diccionario actúa como una “tabla de equivalencias”.\n",
    "# Sirve para corregir variaciones comunes de columnas que cambian\n",
    "# cuando los equipos agregan transformaciones o nuevas fuentes.\n",
    "\n",
    "name_mapping = {\n",
    "    \"customer_id\": [\"cust_id\", \"client_id\", \"id_cliente\"],\n",
    "    \"monthly_charges\": [\"monthlycharge\", \"costo_mensual\"],\n",
    "    \"tenure_months\": [\"tenure\", \"meses_tenencia\"],\n",
    "    \"gender\": [\"Genero\", \"Gender_ID\"],\n",
    "    \"TotalCharges\": [\"Total_Charges\", \"TotalCharge\"]\n",
    "}\n",
    "\n",
    "# ===============================================================\n",
    "# 3. RENOMBRAR COLUMNAS BASADAS EN EL MAPEO\n",
    "# ===============================================================\n",
    "df_fixed = df_scoring\n",
    "cols_scoring = df_scoring.columns\n",
    "\n",
    "print(\"\\n\uD83D\uDD04 Normalizando nombres según lista de variantes...\")\n",
    "\n",
    "for target_col, variants in name_mapping.items():\n",
    "    for alt_name in variants:\n",
    "        if alt_name in cols_scoring and target_col not in cols_scoring:\n",
    "            print(f\"   ↪️ Renombrando '{alt_name}' → '{target_col}'\")\n",
    "            df_fixed = df_fixed.withColumnRenamed(alt_name, target_col)\n",
    "            break  # detenemos tras renombrar una coincidencia\n",
    "\n",
    "cols_scoring = df_fixed.columns  # refrescar\n",
    "\n",
    "# ===============================================================\n",
    "# 4. AGREGAR COLUMNAS FALTANTES\n",
    "# ===============================================================\n",
    "# Cuando el scoring recibe un archivo sin todas las columnas\n",
    "# (caso real: nuevas conexiones de clientes, versiones del upstream),\n",
    "# el modelo se rompe.\n",
    "\n",
    "missing_cols = [c for c in expected_cols if c not in cols_scoring]\n",
    "\n",
    "print(\"\\n Verificando columnas faltantes...\")\n",
    "\n",
    "for col_name in missing_cols:\n",
    "    print(f\"   ⚠️ '{col_name}' no existe en scoring → creando con NULL.\")\n",
    "    df_fixed = df_fixed.withColumn(col_name, lit(None))\n",
    "\n",
    "cols_scoring = df_fixed.columns\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# 5. REMOVER COLUMNAS EXTRA\n",
    "# ===============================================================\n",
    "extra_cols = [c for c in cols_scoring if c not in expected_cols]\n",
    "\n",
    "if extra_cols:\n",
    "    print(f\"\\n Eliminando columnas extra no usadas por el modelo: {extra_cols}\")\n",
    "\n",
    "df_fixed = df_fixed.select(expected_cols)\n",
    "\n",
    "# ===============================================================\n",
    "# 6. CORREGIR TIPOS DE DATO (Type Drift)\n",
    "# ===============================================================\n",
    "print(\"\\n\uD83D\uDEE0 Verificando consistencia de tipos...\")\n",
    "\n",
    "current_schema = dict(df_fixed.dtypes)\n",
    "\n",
    "for col_name, expected_type in expected_schema.items():\n",
    "    if current_schema[col_name] != expected_type:\n",
    "        print(f\"   \uD83D\uDD27 '{col_name}' ({current_schema[col_name]} → {expected_type})\")\n",
    "        df_fixed = df_fixed.withColumn(col_name, col(col_name).cast(expected_type))\n",
    "\n",
    "# ===============================================================\n",
    "# 7. LOG COMPLETO A MLFLOW\n",
    "# ===============================================================\n",
    "drift_report = {\n",
    "    \"missing_columns\": missing_cols,\n",
    "    \"extra_columns\": extra_cols,\n",
    "    \"name_mapping_used\": name_mapping,\n",
    "}\n",
    "\n",
    "mlflow.log_dict(drift_report, \"schema_drift_report.json\")\n",
    "\n",
    "print(\"\\n\uD83D\uDCDD Schema Drift Report registrado en MLflow.\")\n",
    "print(\"\uD83C\uDF89 Esquema final compatible con el modelo listo para scoring.\")\n",
    "\n",
    "df_final_scoring = df_fixed\n",
    "df_final_scoring.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3cce51a-6851-4743-969e-e1d2b4f150be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Escenario 3.2:  Carga incorrecta de modelo en MLflow\n",
    "\n",
    "### Diagnóstico y Corrección\n",
    "**Qué estaba mal:**\n",
    "1.  **Nombre Incorrecto:** El código intentaba cargar `churn_model_prod` cuando el modelo registrado se llama `churn_model`.\n",
    "2.  **Stage Inexistente:** No existía un stage `Production` configurado.\n",
    "3.  **Falta de Metadatos:** El modelo carecía de etiquetas de trazabilidad requeridas por el negocio.\n",
    "\n",
    "**Corrección:**\n",
    "*   Se utilizó `MlflowClient` para **listar y verificar** la existencia del modelo y sus versiones antes de cargar.\n",
    "*   Se implementó la carga dinámica apuntando a la **última versión disponible** (`latest_version`) en lugar de un stage hardcodeado.\n",
    "*    Se inyectaron los metadatos solicitados (framework, project_id) directamente en la versión específica del modelo para mejorar la gobernanza y trazabilidad.\n",
    "\n",
    "**Por qué es adecuada:**\n",
    "Esta solución elimina la fragilidad de depender de nombres y estados \"hardcodeados\". Al inspeccionar programáticamente el registro antes de cargar, el script se vuelve robusto ante nuevos despliegues y garantiza que siempre se utilice el artefacto más reciente y correctamente etiquetado para auditoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1e24ae2-0a49-4e29-90d8-3023b024ac1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "import mlflow\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# ============================================================\n",
    "# 1. DEFINICIÓN DE RECURSOS\n",
    "# ============================================================\n",
    "model_name = \"churn_model\" \n",
    "\n",
    "# ============================================================\n",
    "# 2. LISTAR Y SELECCIONAR VERSIÓN\n",
    "# ============================================================\n",
    "# Buscamos todas las versiones\n",
    "try:\n",
    "    versions = client.search_model_versions(f\"name='{model_name}'\")\n",
    "except Exception as e:\n",
    "    print(f\" El modelo '{model_name}' no existe en el registro.\")\n",
    "    versions = []\n",
    "\n",
    "if not versions:\n",
    "    print(\"No se encontraron versiones disponibles. Deteniendo proceso.\")\n",
    "    # En un script real, aquí haríamos un raise Exception o exit()\n",
    "else:\n",
    "    print(f\"✅ Se encontraron {len(versions)} versiones.\")\n",
    "    \n",
    "    # Ordenamos y tomamos la última\n",
    "    versions_sorted = sorted(versions, key=lambda x: int(x.version), reverse=True)\n",
    "    latest_version_obj = versions_sorted[0]\n",
    "    latest_version_id = latest_version_obj.version\n",
    "    \n",
    "    print(f\"   -> Seleccionada la versión: v{latest_version_id} (Stage: {latest_version_obj.current_stage})\")\n",
    "\n",
    "    # ============================================================\n",
    "    # 3. CARGA DEL MODELO\n",
    "    # ============================================================\n",
    "    # Construimos la URI dinámica apuntando a la versión específica\n",
    "    model_uri = f\"models:/{model_name}/{latest_version_id}\"\n",
    "    print(f\"\\n\uD83D\uDE80 Cargando modelo desde: {model_uri}\")\n",
    "    \n",
    "    try:\n",
    "        # Usamos sklearn para carga nativa (o pyfunc si es genérico)\n",
    "        model = mlflow.pyfunc.load_model(model_uri)\n",
    "        print(\" Modelo cargado exitosamente en memoria.\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error crítico cargando el artefacto: {e}\")\n",
    "\n",
    "    # ============================================================\n",
    "    # 4. GESTIÓN DE METADATOS (TAGS)\n",
    "    # ============================================================\n",
    "    # Aplicamos etiquetas a la VERSIÓN específica que acabamos de validar.\n",
    "    # Esto permite saber qué framework usó esa versión puntual.\n",
    "    tags = {\n",
    "        \"model_framework\": \"sklearn\",\n",
    "        \"project_id\": \"123456\",\n",
    "        \"model_type\": \"regression\"\n",
    "    }\n",
    "\n",
    "    print(\"\\n\uD83C\uDFF7 Aplicando etiquetas de gobernanza...\")\n",
    "    for k, v in tags.items():\n",
    "        client.set_model_version_tag(\n",
    "            name=model_name,\n",
    "            version=latest_version_id,\n",
    "            key=k,\n",
    "            value=v\n",
    "        )\n",
    "        print(f\"   + Tag '{k}' añadido a versión {latest_version_id}\")\n",
    "\n",
    "    print(\"\\n\uD83C\uDF89 Proceso de corrección y carga finalizado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0cb6fd27-6599-4a97-b9fc-d585683f8eac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Escenario 3.3 – Sistema RAG que siempre devuelve contexto vacío\n",
    "\n",
    "### Diagnóstico y Corrección\n",
    "\n",
    "**Problema identificado:**  \n",
    "La función `retrieve_relevant_chunks` original devolvía siempre un DataFrame vacío.  \n",
    "Esto ocurría por dos causas típicas:\n",
    "1. El ordenamiento usaba los valores **ascendentes** en lugar de descendentes.  \n",
    "2. La comparación del umbral se aplicaba antes de ordenar, filtrando todos los registros.\n",
    "\n",
    "**Solución aplicada:**  \n",
    "Implementé una versión mínima y correcta del recuperador usando NumPy:\n",
    "\n",
    "- Se cargan los embeddings a memoria una sola vez.\n",
    "- La similitud se calcula mediante **producto punto vectorizado**.\n",
    "- Se seleccionan los *k* chunks con mayor score usando `argsort()[-k:][::-1]`.\n",
    "\n",
    "**Por qué funciona:**  \n",
    "La recuperación ya no depende de operaciones fila por fila ni umbrales incorrectos.  \n",
    "El vectorizado garantiza que siempre se obtienen los documentos más similares y que el bloque de generación del LLM llega a la rama donde hay contexto válido.\n",
    "\n",
    "**Resultado:**  \n",
    "La función devuelve chunks reales, el sistema RAG tiene contexto y el LLM genera respuestas basadas en ese contenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a1b978e-860d-4034-9217-1b4fc9de1a99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Cargar embeddings en memoria (solo una vez)\n",
    "df_local = df_spark_embeddings.toPandas()\n",
    "\n",
    "emb_matrix = np.stack(df_local[\"embedding\"].values)  # matriz NumPy (N x d)\n",
    "chunk_texts = df_local[\"chunk_text\"].values          # array de textos\n",
    "\n",
    "def retrieve_relevant_chunks(query_emb, k=3):\n",
    "    \"\"\"\n",
    "    Recupera los k chunks más similares a la embedding de la consulta.\n",
    "    Optimizado usando NumPy (sin UDFs y sin toPandas dentro).\n",
    "    \"\"\"\n",
    "\n",
    "    # A. Similaridad (Producto Punto)\n",
    "    sims = np.dot(emb_matrix, query_emb)\n",
    "\n",
    "    # B. Top-k (ordenamos descendente)\n",
    "    top_idx = sims.argsort()[-k:][::-1]\n",
    "\n",
    "    # C. Retornar texto + score\n",
    "  \n",
    "    return [(chunk_texts[i], float(sims[i])) for i in top_idx]\n",
    "\n",
    "\n",
    "# ===========================================================\n",
    "# Pregunta de prueba — debe generar contexto válido\n",
    "# ===========================================================\n",
    "pregunta = \"¿Qué es Azure Databricks?\"\n",
    "query_emb = embedding_model.encode(pregunta)\n",
    "\n",
    "top_chunks = retrieve_relevant_chunks(query_emb, k=3)\n",
    "\n",
    "# Preparar el texto para el generador\n",
    "context_str = \"\\n\".join([t for t, s in top_chunks])\n",
    "\n",
    "# 3. Vañidación\n",
    "if len(top_chunks) > 0:\n",
    "    print(\"\\n VALIDACIÓN EXITOSA: Entró a la rama con contexto.\")\n",
    "\n",
    "    answer = llm_generate(pregunta, context_str)\n",
    "    print(f\"   Resultado final: {answer}\")\n",
    "else:\n",
    "    print(\"\\n ERROR: Rama vacía (El bug persiste).\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "20_escenarios_soporte",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}