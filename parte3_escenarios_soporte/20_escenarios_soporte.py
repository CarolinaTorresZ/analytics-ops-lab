# Databricks notebook source
# MAGIC %md
# MAGIC # Parte 3:   Escenarios de Soporte
# MAGIC *   **Autor:** Carolina Torres Zapata
# MAGIC *   **Fecha:** 2025-11-24
# MAGIC *   **Contexto:** En la operaci√≥n diaria, los "caminos felices" son raros. Los datos cambian (Schema Drift), los despliegues fallan por mala configuraci√≥n y el c√≥digo optimizado incorrectamente rompe la producci√≥n.
# MAGIC *   **Objetivo del Notebook:**
# MAGIC Resolver tres incidentes simulados aplicando buenas pr√°cticas:
# MAGIC      1.  **Escenario 3.1:** Robustecer un pipeline de inferencia ante cambios inesperados en los datos de entrada.
# MAGIC      2.  **Escenario 3.2:** Corregir la carga de modelos utilizando la API program√°tica de MLflow para evitar errores de hardcoding.
# MAGIC      3.  **Escenario 3.3:** Reparar un bug l√≥gico en el sistema de recuperaci√≥n (RAG) utilizando operaciones vectorizadas.

# COMMAND ----------

# MAGIC %md
# MAGIC ## Escenario 3.1: Schema drift en datos de entrada
# MAGIC
# MAGIC ### Diagn√≥stico y Correcci√≥n
# MAGIC
# MAGIC **Qu√© estaba mal:**
# MAGIC El uso directo (`df_scoring.select(cols)`) es fr√°gil; falla inmediatamente con un `AnalysisException` si el dataset de inferencia tiene una columna menos o un nombre diferente (Drift), y no gestiona columnas nuevas que podr√≠an ensuciar el proceso.
# MAGIC
# MAGIC **Correcci√≥n:**
# MAGIC 1.  **Renombrado:** Normalizaci√≥n de nombres mediante un diccionario de equivalencias para manejar variaciones comunes.
# MAGIC 2.  **Imputaci√≥n:** Creaci√≥n autom√°tica de columnas faltantes con `NULL` para mantener el esquema requerido.
# MAGIC 3. **Validaci√≥n de Tipos:** Conversi√≥n expl√≠cita (`cast`) de cada columna al tipo de dato esperado por el modelo.
# MAGIC 3.  **Selecci√≥n:** Filtrado final expl√≠cito para ordenar columnas y descartar atributos extra no utilizados por el modelo.
# MAGIC
# MAGIC **Por qu√© es adecuada:**
# MAGIC Esta soluci√≥n asegura la **resiliencia operativa**. El pipeline no se detiene por cambios menores en la fuente, garantizando que el modelo siempre reciba la matriz de caracter√≠sticas exacta que espera para predecir, protegiendo la continuidad del servicio.

# COMMAND ----------

# =====================================
# IMPORTAR LIBRER√çAS
# =====================================
from pyspark.sql.functions import col, lit
import mlflow

# =====================================
# 1. ESQUEMA ESPERADO
# =====================================
expected_cols = df_train.columns
expected_schema = dict(df_train.dtypes)

print(f"Columnas esperadas por el modelo: {len(expected_cols)}")

# ===============================================================
# 2. MAPEO DE NOMBRES DE COLUMNAS (Name Normalization)
# ===============================================================
# Este diccionario act√∫a como una ‚Äútabla de equivalencias‚Äù.
# Sirve para corregir variaciones comunes de columnas que cambian
# cuando los equipos agregan transformaciones o nuevas fuentes.

name_mapping = {
    "customer_id": ["cust_id", "client_id", "id_cliente"],
    "monthly_charges": ["monthlycharge", "costo_mensual"],
    "tenure_months": ["tenure", "meses_tenencia"],
    "gender": ["Genero", "Gender_ID"],
    "TotalCharges": ["Total_Charges", "TotalCharge"]
}

# ===============================================================
# 3. RENOMBRAR COLUMNAS BASADAS EN EL MAPEO
# ===============================================================
df_fixed = df_scoring
cols_scoring = df_scoring.columns

print("\nüîÑ Normalizando nombres seg√∫n lista de variantes...")

for target_col, variants in name_mapping.items():
    for alt_name in variants:
        if alt_name in cols_scoring and target_col not in cols_scoring:
            print(f"   ‚Ü™Ô∏è Renombrando '{alt_name}' ‚Üí '{target_col}'")
            df_fixed = df_fixed.withColumnRenamed(alt_name, target_col)
            break  # detenemos tras renombrar una coincidencia

cols_scoring = df_fixed.columns  # refrescar

# ===============================================================
# 4. AGREGAR COLUMNAS FALTANTES
# ===============================================================
# Cuando el scoring recibe un archivo sin todas las columnas
# (caso real: nuevas conexiones de clientes, versiones del upstream),
# el modelo se rompe.

missing_cols = [c for c in expected_cols if c not in cols_scoring]

print("\n Verificando columnas faltantes...")

for col_name in missing_cols:
    print(f"   ‚ö†Ô∏è '{col_name}' no existe en scoring ‚Üí creando con NULL.")
    df_fixed = df_fixed.withColumn(col_name, lit(None))

cols_scoring = df_fixed.columns


# ===============================================================
# 5. REMOVER COLUMNAS EXTRA
# ===============================================================
extra_cols = [c for c in cols_scoring if c not in expected_cols]

if extra_cols:
    print(f"\n Eliminando columnas extra no usadas por el modelo: {extra_cols}")

df_fixed = df_fixed.select(expected_cols)

# ===============================================================
# 6. CORREGIR TIPOS DE DATO (Type Drift)
# ===============================================================
print("\nüõ† Verificando consistencia de tipos...")

current_schema = dict(df_fixed.dtypes)

for col_name, expected_type in expected_schema.items():
    if current_schema[col_name] != expected_type:
        print(f"   üîß '{col_name}' ({current_schema[col_name]} ‚Üí {expected_type})")
        df_fixed = df_fixed.withColumn(col_name, col(col_name).cast(expected_type))

# ===============================================================
# 7. LOG COMPLETO A MLFLOW
# ===============================================================
drift_report = {
    "missing_columns": missing_cols,
    "extra_columns": extra_cols,
    "name_mapping_used": name_mapping,
}

mlflow.log_dict(drift_report, "schema_drift_report.json")

print("\nüìù Schema Drift Report registrado en MLflow.")
print("üéâ Esquema final compatible con el modelo listo para scoring.")

df_final_scoring = df_fixed
df_final_scoring.show()


# COMMAND ----------

# MAGIC %md
# MAGIC ## Escenario 3.2:  Carga incorrecta de modelo en MLflow
# MAGIC
# MAGIC ### Diagn√≥stico y Correcci√≥n
# MAGIC **Qu√© estaba mal:**
# MAGIC 1.  **Nombre Incorrecto:** El c√≥digo intentaba cargar `churn_model_prod` cuando el modelo registrado se llama `churn_model`.
# MAGIC 2.  **Stage Inexistente:** No exist√≠a un stage `Production` configurado.
# MAGIC 3.  **Falta de Metadatos:** El modelo carec√≠a de etiquetas de trazabilidad requeridas por el negocio.
# MAGIC
# MAGIC **Correcci√≥n:**
# MAGIC *   Se utiliz√≥ `MlflowClient` para **listar y verificar** la existencia del modelo y sus versiones antes de cargar.
# MAGIC *   Se implement√≥ la carga din√°mica apuntando a la **√∫ltima versi√≥n disponible** (`latest_version`) en lugar de un stage hardcodeado.
# MAGIC *    Se inyectaron los metadatos solicitados (framework, project_id) directamente en la versi√≥n espec√≠fica del modelo para mejorar la gobernanza y trazabilidad.
# MAGIC
# MAGIC **Por qu√© es adecuada:**
# MAGIC Esta soluci√≥n elimina la fragilidad de depender de nombres y estados "hardcodeados". Al inspeccionar program√°ticamente el registro antes de cargar, el script se vuelve robusto ante nuevos despliegues y garantiza que siempre se utilice el artefacto m√°s reciente y correctamente etiquetado para auditor√≠a.

# COMMAND ----------

from mlflow.tracking import MlflowClient
import mlflow

client = MlflowClient()

# ============================================================
# 1. DEFINICI√ìN DE RECURSOS
# ============================================================
model_name = "churn_model" 

# ============================================================
# 2. LISTAR Y SELECCIONAR VERSI√ìN
# ============================================================
# Buscamos todas las versiones
try:
    versions = client.search_model_versions(f"name='{model_name}'")
except Exception as e:
    print(f" El modelo '{model_name}' no existe en el registro.")
    versions = []

if not versions:
    print("No se encontraron versiones disponibles. Deteniendo proceso.")
    # En un script real, aqu√≠ har√≠amos un raise Exception o exit()
else:
    print(f"‚úÖ Se encontraron {len(versions)} versiones.")
    
    # Ordenamos y tomamos la √∫ltima
    versions_sorted = sorted(versions, key=lambda x: int(x.version), reverse=True)
    latest_version_obj = versions_sorted[0]
    latest_version_id = latest_version_obj.version
    
    print(f"   -> Seleccionada la versi√≥n: v{latest_version_id} (Stage: {latest_version_obj.current_stage})")

    # ============================================================
    # 3. CARGA DEL MODELO
    # ============================================================
    # Construimos la URI din√°mica apuntando a la versi√≥n espec√≠fica
    model_uri = f"models:/{model_name}/{latest_version_id}"
    print(f"\nüöÄ Cargando modelo desde: {model_uri}")
    
    try:
        # Usamos sklearn para carga nativa (o pyfunc si es gen√©rico)
        model = mlflow.pyfunc.load_model(model_uri)
        print(" Modelo cargado exitosamente en memoria.")
    except Exception as e:
        print(f" Error cr√≠tico cargando el artefacto: {e}")

    # ============================================================
    # 4. GESTI√ìN DE METADATOS (TAGS)
    # ============================================================
    # Aplicamos etiquetas a la VERSI√ìN espec√≠fica que acabamos de validar.
    # Esto permite saber qu√© framework us√≥ esa versi√≥n puntual.
    tags = {
        "model_framework": "sklearn",
        "project_id": "123456",
        "model_type": "regression"
    }

    print("\nüè∑ Aplicando etiquetas de gobernanza...")
    for k, v in tags.items():
        client.set_model_version_tag(
            name=model_name,
            version=latest_version_id,
            key=k,
            value=v
        )
        print(f"   + Tag '{k}' a√±adido a versi√≥n {latest_version_id}")

    print("\nüéâ Proceso de correcci√≥n y carga finalizado.")

# COMMAND ----------

# MAGIC %md
# MAGIC ## Escenario 3.3 ‚Äì Sistema RAG que siempre devuelve contexto vac√≠o
# MAGIC
# MAGIC ### Diagn√≥stico y Correcci√≥n
# MAGIC
# MAGIC **Problema identificado:**  
# MAGIC La funci√≥n `retrieve_relevant_chunks` original devolv√≠a siempre un DataFrame vac√≠o.  
# MAGIC Esto ocurr√≠a por dos causas t√≠picas:
# MAGIC 1. El ordenamiento usaba los valores **ascendentes** en lugar de descendentes.  
# MAGIC 2. La comparaci√≥n del umbral se aplicaba antes de ordenar, filtrando todos los registros.
# MAGIC
# MAGIC **Soluci√≥n aplicada:**  
# MAGIC Implement√© una versi√≥n m√≠nima y correcta del recuperador usando NumPy:
# MAGIC
# MAGIC - Se cargan los embeddings a memoria una sola vez.
# MAGIC - La similitud se calcula mediante **producto punto vectorizado**.
# MAGIC - Se seleccionan los *k* chunks con mayor score usando `argsort()[-k:][::-1]`.
# MAGIC
# MAGIC **Por qu√© funciona:**  
# MAGIC La recuperaci√≥n ya no depende de operaciones fila por fila ni umbrales incorrectos.  
# MAGIC El vectorizado garantiza que siempre se obtienen los documentos m√°s similares y que el bloque de generaci√≥n del LLM llega a la rama donde hay contexto v√°lido.
# MAGIC
# MAGIC **Resultado:**  
# MAGIC La funci√≥n devuelve chunks reales, el sistema RAG tiene contexto y el LLM genera respuestas basadas en ese contenido.

# COMMAND ----------

import numpy as np

# Cargar embeddings en memoria (solo una vez)
df_local = df_spark_embeddings.toPandas()

emb_matrix = np.stack(df_local["embedding"].values)  # matriz NumPy (N x d)
chunk_texts = df_local["chunk_text"].values          # array de textos

def retrieve_relevant_chunks(query_emb, k=3):
    """
    Recupera los k chunks m√°s similares a la embedding de la consulta.
    Optimizado usando NumPy (sin UDFs y sin toPandas dentro).
    """

    # A. Similaridad (Producto Punto)
    sims = np.dot(emb_matrix, query_emb)

    # B. Top-k (ordenamos descendente)
    top_idx = sims.argsort()[-k:][::-1]

    # C. Retornar texto + score
  
    return [(chunk_texts[i], float(sims[i])) for i in top_idx]


# ===========================================================
# Pregunta de prueba ‚Äî debe generar contexto v√°lido
# ===========================================================
pregunta = "¬øQu√© es Azure Databricks?"
query_emb = embedding_model.encode(pregunta)

top_chunks = retrieve_relevant_chunks(query_emb, k=3)

# Preparar el texto para el generador
context_str = "\n".join([t for t, s in top_chunks])

# 3. Va√±idaci√≥n
if len(top_chunks) > 0:
    print("\n VALIDACI√ìN EXITOSA: Entr√≥ a la rama con contexto.")

    answer = llm_generate(pregunta, context_str)
    print(f"   Resultado final: {answer}")
else:
    print("\n ERROR: Rama vac√≠a (El bug persiste).")
