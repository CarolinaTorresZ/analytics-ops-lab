# Prueba TÃ©cnica â€“ Soporte a la OperaciÃ³n de Modelos AnalÃ­ticos (IT)

**Candidata:** Carolina Torres Zapata  
**Fecha:** 24 de Noviembre 2025  
**Plataforma:** Databricks (Community/Free Edition)

## ğŸ“‹ Resumen Ejecutivo
Este repositorio contiene la soluciÃ³n tÃ©cnica enfocada en la **operaciÃ³n, diagnÃ³stico y mantenimiento** de flujos analÃ­ticos, priorizando la robustez y la trazabilidad (MLOps) sobre la complejidad algorÃ­tmica, en cumplimiento con los criterios de evaluaciÃ³n.

El proyecto demuestra:
1.  Flujo End-to-End de ML con trazabilidad **MLflow**.
2.  ImplementaciÃ³n de un sistema **RAG** (Retrieval-Augmented Generation) funcional y seguro.
3.  Capacidad de diagnÃ³stico y **correcciÃ³n de cÃ³digo (Debugging)** en escenarios de soporte crÃ­ticos.

---

## ğŸ“‚ Estructura del Proyecto

El repositorio estÃ¡ organizado siguiendo el flujo lÃ³gico de la prueba y una arquitectura de datos ordenada:

```text
.
â”œâ”€â”€ parte1_ciclo_modelo/          # Flujo MLOps End-to-End (Churn)
â”‚   â”œâ”€â”€ 01_preparacion_y_eda.ipynb
â”‚   â”œâ”€â”€ 02_entrenamiento_y_tracking.ipynb
â”‚   â”œâ”€â”€ 03_a_registro_y_carga_artefactos.ipynb  (Enfoque Resiliente/Fallback)
â”‚   â””â”€â”€ 03_b_registro_y_carga_uc.ipynb          (Enfoque Enterprise/Unity Catalog)
â”‚
â”œâ”€â”€ parte2_sistema_rag/           # Sistema de Preguntas y Respuestas
â”‚   â”œâ”€â”€ 09_rag_ingesta.ipynb
â”‚   â”œâ”€â”€ 10_rag_chunking.ipynb
â”‚   â”œâ”€â”€ 11_rag_embeddings.ipynb
â”‚   â””â”€â”€ 12_rag_retrieval_y_llm.ipynb
â”‚
â”œâ”€â”€ parte3_escenarios_soporte/    # ResoluciÃ³n de Incidentes
â”‚   â””â”€â”€ 20_escenarios_soporte.ipynb
â”‚
â”œâ”€â”€ data/                         # SimulaciÃ³n Data Lake (Medallion Architecture)
â”‚   â”œâ”€â”€ bronze/                   # Datos crudos (csv, txt)
â”‚   â”œâ”€â”€ silver/                   # Datos procesados y tablas delta
â”‚   â””â”€â”€ ml_models/                
â”‚
â””â”€â”€ README.md                     # DocumentaciÃ³n tÃ©cnica
```

## âš™ï¸ GuÃ­a de EjecuciÃ³n (CÃ³mo ejecutar los notebooks)

Los notebooks estÃ¡n numerados secuencialmente dentro de sus carpetas para facilitar la ejecuciÃ³n. Se recomienda seguir este orden:

### 1. ğŸ“‚ `parte1_ciclo_modelo/`
*   **01_preparacion_y_eda:** Ejecutar primero para limpiar los datos y generar el dataset base.
*   **02_entrenamiento_y_tracking:** Entrena los modelos y genera los artefactos en MLflow.
*   **03_registro_y_carga:** *Nota:* Se incluyen dos versiones para cubrir los puntos 4.a y 4.b de las instrucciones:
    *   `03_a_registro_y_carga_artefactos`: Ejecutar si no se tiene acceso a Unity Catalog (Uso de `runs:/`).
    *   `03_b_registro_y_carga_uc`: Ejecutar para validar el flujo ideal con Unity Catalog (`models:/`).

### 2. ğŸ“‚ `parte2_sistema_rag/`
*   **09_rag_ingesta:** Descarga y limpieza del HTML.
*   **10_rag_chunking:** SegmentaciÃ³n semÃ¡ntica.
*   **11_rag_embeddings:** GeneraciÃ³n de vectores.
*   **12_rag_retrieval_y_llm:** OrquestaciÃ³n final y chat con el LLM.

### 3. ğŸ“‚ `parte3_escenarios_soporte/`
*   **20_escenarios_soporte:** Contiene la resoluciÃ³n de los tres incidentes en un solo notebook autocontenido.

---

## ğŸ›  Parte 1: Ciclo de vida de un modelo (Enfoque Operacional)

Se implementÃ³ un pipeline completo de MLOps para predecir la fuga de clientes.

### 1. InformaciÃ³n del Dataset
*   **Nombre:** Telco Customer Churn (IBM/Kaggle).
*   **URL de Origen:** [Kaggle - Telco Customer Churn](https://www.kaggle.com/datasets/blastchar/telco-customer-churn)
*   **Variable Objetivo:** `Churn` (Binaria: Yes/No).

### 2. EjecuciÃ³n y Estrategia
*   **PreparaciÃ³n:** Limpieza de datos, conversiÃ³n de tipos numÃ©ricos y manejo de nulos.
*   **Entrenamiento:** Se entrenaron mÃºltiples modelos (Logistic Regression, Random Forest) registrando mÃ©tricas (AUC, Accuracy) y parÃ¡metros en **MLflow Tracking** para garantizar la auditabilidad del experimento.
*   **Despliegue HÃ­brido (DecisiÃ³n TÃ©cnica):**
    *   Se incluyen **dos estrategias** de carga en el paso 3:
    *   `03_a`: Carga basada en **Artefactos (Run ID)** Demuestra cÃ³mo cargar el modelo productivo directamente desde los **Artefactos de MLflow** usando el `Run ID`, asegurando que la operaciÃ³n no se detenga por fallos en el catÃ¡logo central.
    *   `03_b`: Carga basada en **Unity Catalog**. EstÃ¡ndar de gobierno para producciÃ³n ("Model Registry").

---

## ğŸ¤– Parte 2: Sistema RAG MÃ­nimo (Montaje y OperaciÃ³n)

Se construyÃ³ un sistema de *Retrieval-Augmented Generation* modularizado para consultar documentaciÃ³n tÃ©cnica.

### 1. Fuente del Documento
*   **Tema Principal:** IntroducciÃ³n a Azure Databricks (Plataforma unificada de anÃ¡lisis).
*   **URL:** [DocumentaciÃ³n Oficial Microsoft Learn](https://learn.microsoft.com/es-es/azure/databricks/introduction/)

### 2. Arquitectura TÃ©cnica
*   **Ingesta y Chunking:** ExtracciÃ³n limpia de HTML y segmentaciÃ³n semÃ¡ntica  por **pÃ¡rrafos completos** con un lÃ­mite de 1000 caracteres. Esto preserva el contexto semÃ¡ntico mejor que el corte arbitrario por longitud fija.
*   **Embeddings (DecisiÃ³n de Costo/Eficiencia):**
    *   Se utilizÃ³ el modelo Open Source **`sentence-transformers/all-MiniLM-L6-v2`** ejecutado localmente.
    *   *JustificaciÃ³n:* Dado que el entorno gratuito no posee endpoints de embeddings de pago (Azure OpenAI / Databricks Foundation Models provisionados). Permite generar embeddings de alta calidad localmente en el driver del cluster sin costos adicionales ni dependencias de API externas.
*   **Retrieval:** BÃºsqueda vectorial mediante similitud de coseno (Producto punto).
*   **LLM & Grounding:**
    *   Se utilizÃ³ una funciÃ³n de "Health Check" que busca dinÃ¡micamente endpoints activos (Llama 3) para garantizar la resiliencia del notebook.
    *   Se implementÃ³ un *System Prompt* estricto para evitar alucinaciones: si la respuesta no estÃ¡ en el contexto, el modelo responde: *"La informaciÃ³n disponible no menciona este tema"*.

---

## ğŸš¨ Parte 3: Escenarios de Soporte (DiagnÃ³stico y CorrecciÃ³n)

ResoluciÃ³n de bugs crÃ­ticos y mejora de cÃ³digo para producciÃ³n.

| Escenario | Problema Detectado | SoluciÃ³n Implementada |
| :--- | :--- | :--- |
| **3.1 Schema Drift** | El pipeline fallaba ante cambios de nombres o nuevas columnas. | Se implementÃ³ un esquema defensivo: Mapeo de sinÃ³nimos, imputaciÃ³n de nulos para columnas faltantes y casting explÃ­cito de tipos. |
| **3.2 Carga de Modelo** | Uso de nombres y stages "hardcodeados" que no existÃ­an. | Uso de `MlflowClient` para bÃºsqueda dinÃ¡mica de la Ãºltima versiÃ³n disponible e inyecciÃ³n de etiquetas de gobierno (`project_id`, `framework`). |
| **3.3 RAG Bug** | RecuperaciÃ³n vacÃ­a por error lÃ³gico en ordenamiento. | Reescritura usando **NumPy vectorizado**: cÃ¡lculo de producto punto y uso de `argsort` descendente para garantizar la recuperaciÃ³n de los Top-K documentos. |

---

## ğŸ’¾ Acceso a Datos (SimulaciÃ³n Medallion)

Para facilitar la validaciÃ³n de la prueba sin acceso directo al Workspace de Databricks, se adjunta en este repositorio la carpeta **/data** simulando la arquitectura Medallion con los resultados reales de la ejecuciÃ³n:

*   `data/bronze/`: Archivos crudos (CSV Kaggle, TXT Azure Docs).
*   `data/silver/`: Datos procesados (`churn_data`,`clean_data` ,`rag_chunks`, `rag_embeddings`).
*   `ml_models/` :  Contiene el **artefacto serializado**  (`churn_model_prod.pkl`).
    *   *PropÃ³sito:* Este archivo permite validar el modelo entrenado localmente (usando `joblib.load`) sin necesidad de conectarse al servidor de MLflow o Unity Catalog de Databricks.

*Nota: Los notebooks estÃ¡n configurados para leer tablas (`spark.read.table`), representando el entorno productivo real.*

---

## âš ï¸ Limitaciones y Workarounds

1.  **Entorno Gratuito (Databricks Community):**
    *   *LimitaciÃ³n:* No hay acceso completo a ciertas funcionalidades empresariales de Unity Catalog (Governance avanzado) ni GPUs para entrenamiento pesado.
    *   *Workaround:* Se utilizaron **Unity Catalog Volumes** para la gestiÃ³n de archivos y modelos ligeros (Scikit-Learn / Sentence-Transformers) que corren eficientemente en CPU.

2.  **API de LLM:**
    *   El notebook 12 asume la existencia de un Endpoint de Databricks (`databricks-meta-llama-3...`). Se incluyÃ³ una lÃ³gica de **"Health Check"** que busca dinÃ¡micamente endpoints disponibles para evitar fallos si el nombre del modelo cambia.

---
